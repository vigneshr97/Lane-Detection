{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, the camera calibration is computed using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6927ce7c87b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TkAgg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import os\n",
    "\n",
    "cal_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "def calibrate():\n",
    "\tobjp = np.zeros((6*9,3), np.float32)\n",
    "\tobjp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\tobjpoints = []\n",
    "\timgpoints = []\n",
    "\tfor idx, fname in enumerate(cal_images):\n",
    "\t\timage = cv2.imread(fname)\n",
    "\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\tret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\t\tprint(fname+' '+str(ret))\n",
    "\t\tif ret == True:\n",
    "\t\t\tobjpoints.append(objp)\n",
    "\t\t\timgpoints.append(corners)\n",
    "\t\t\t#cv2.drawChessboardCorners(img, (8,6), corners, ret)\n",
    "\treturn objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, the image is undistorted using the obtained camera matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, objpoints, imgpoints):\n",
    "\tret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img.shape[1], img.shape[0]), None, None)\n",
    "\tundist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\treturn undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The image is converted to HLS and a perspective transform is applied to obtain a Bird's eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_pipeline(img, s_thresh = (180, 255), sxthresh = (10, 100)):\n",
    "\thls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\tl_channel = hls[:,:,1]\n",
    "\ts_channel = hls[:,:,2]\n",
    "\tsobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0, ksize = 3)\n",
    "\tsobely = cv2.Sobel(s_channel, cv2.CV_64F, 0, 1, ksize = 3) \n",
    "\tabs_sobelx = np.absolute(sobelx)\n",
    "\tscaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\t#abs_sobel_dir = np.arctan2(np.absolute(sobely),np.absolute(sobelx))\n",
    "\n",
    "    #sdirbinary = np.zeros_like(scaled_sobel)\n",
    "    #sdirbinary[((abs_sobel_dir>=dir_thresh[0])&(abs_sobel_dir<=dir_thresh[1]))] = 1\n",
    "\n",
    "\tsxbinary = np.zeros_like(scaled_sobel)\n",
    "\tsxbinary[(scaled_sobel >= sxthresh[0]) & (scaled_sobel <= sxthresh[1])] = 1\n",
    "\n",
    "\ts_binary = np.zeros_like(s_channel)\n",
    "\ts_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "\t#both combined\n",
    "\tcombo = np.zeros_like(scaled_sobel)\n",
    "\tcombo[(sxbinary==1)|(s_binary==1)] = 1\n",
    "\tcombo *= 255\n",
    "\t# Stack each channel\n",
    "\t#color_binary = np.dstack((combo,combo,combo))*255\n",
    "\t#color_binary = np.dstack((sxbinary,s_binary), np.dot(sxbinary,s_binary), np.dot(sxbinary,s_binary))) * 255\n",
    "\tcolor_binary = np.dstack((np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\t#cv2.imwrite('combo.jpg',combo)\n",
    "\t#cv2.imwrite('color.jpg',color_binary)\n",
    "\treturn combo\n",
    "\n",
    "def unwarp_image(img):\n",
    "\timg_size = (img.shape[1],img.shape[0])\n",
    "\t#src = np.float32([[img.shape[1]/2-55,img.shape[0]/2+100],[img.shape[1]/2+55,img.shape[0]/2+100],[(img.shape[1]*5/6)+60,img.shape[0]],[img.shape[1]/6-10,img.shape[0]]])\n",
    "\tsrc = np.float32([[img.shape[1]/2-60,img.shape[0]/2+90],[img.shape[1]/2+60,img.shape[0]/2+90],[(img.shape[1]*3/4)+140,img.shape[0]-20],[img.shape[1]/4-110,img.shape[0]-20]])\n",
    "\tdst = np.float32([[img.shape[1]/4,0],[img.shape[1]*3/4,0],[img.shape[1]*3/4,img.shape[0]],[img.shape[1]/4,img.shape[0]]])\n",
    "\tM = cv2.getPerspectiveTransform(src, dst)\n",
    "\tMinv = cv2.getPerspectiveTransform(dst, src)\n",
    "\twarped = cv2.warpPerspective(img, M, (img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\t#warped_color = cv2.warpPerspective(undist, M, (img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\t#cv2.imwrite('warped.jpg',warped)\n",
    "\t#cv2.imwrite('warped_color.jpg',warped_color)\n",
    "\t#cv2.imwrite('original.jpg',img)\n",
    "\treturn warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lane pixels are obtained and a polynomial is fitted. The search is done around the previous polynomial in future iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(img):\n",
    "\thistogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "\tout_img = np.dstack((img, img, img))\n",
    "\tmidpoint = np.int(histogram.shape[0]//2)\n",
    "\tleftx_base = np.argmax(histogram[:midpoint])\n",
    "\trightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\tnwindows = 9\n",
    "\tmargin = 100\n",
    "\tminpix = 50\n",
    "\twindow_height = np.int(img.shape[0]//nwindows)\n",
    "\tnonzero = img.nonzero()\n",
    "\tnonzeroy = np.array(nonzero[0])\n",
    "\tnonzerox = np.array(nonzero[1])\n",
    "\tleftx_current = leftx_base\n",
    "\trightx_current = rightx_base\n",
    "\tleft_lane_inds = []\n",
    "\tright_lane_inds = []\n",
    "\n",
    "\tfor window in range(nwindows):\n",
    "\t\twin_y_low = img.shape[0] - (window+1)*window_height\n",
    "\t\twin_y_high = img.shape[0] - window*window_height\n",
    "\t\twin_xleft_low = leftx_current - margin\n",
    "\t\twin_xleft_high = leftx_current + margin\n",
    "\t\twin_xright_low = rightx_current - margin\n",
    "\t\twin_xright_high = rightx_current + margin\n",
    "\n",
    "\t\t#cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "\t\t#cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "\n",
    "\t\tgood_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\t\tgood_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "\t\tleft_lane_inds.append(good_left_inds)\n",
    "\t\tright_lane_inds.append(good_right_inds)\n",
    "\n",
    "\t\tif len(good_left_inds) > minpix:\n",
    "\t\t\tleftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "\t\tif len(good_right_inds) > minpix:        \n",
    "\t\t\trightx_current = np.int(np.mean(nonzerox[good_right_inds]))    \n",
    "\n",
    "\ttry:\n",
    "\t\tleft_lane_inds = np.concatenate(left_lane_inds)\n",
    "\t\tright_lane_inds = np.concatenate(right_lane_inds)\n",
    "\texcept ValueError:\n",
    "\t\tpass\n",
    "\n",
    "\t# Extract left and right line pixel positions\n",
    "\tleftx = nonzerox[left_lane_inds]\n",
    "\tlefty = nonzeroy[left_lane_inds] \n",
    "\trightx = nonzerox[right_lane_inds]\n",
    "\trighty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\treturn leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(img):\n",
    "\tleftx, lefty, rightx, righty, out_img = find_lane_pixels(img)\n",
    "\tleft_fit = np.polyfit(lefty, leftx, 2)\n",
    "\tright_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\tploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "\ttry:\n",
    "\t\tleft_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "\t\tright_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\texcept TypeError:\n",
    "\t\t# Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "\t\tprint('The function failed to fit a line!')\n",
    "\t\tleft_fitx = 1*ploty**2 + 1*ploty\n",
    "\t\tright_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "\t#storing all the points in the curve\n",
    "\tleftfitpt = []\n",
    "\trightfitpt = []\n",
    "\tfor i in range(len(ploty)):\n",
    "\t\tleftfitpt.append([left_fitx[i],ploty[i]])\n",
    "\t\trightfitpt.append([right_fitx[i],ploty[i]])\n",
    "\t\n",
    "\t## Visualization ##\n",
    "\t# Colors in the left and right lane regions\n",
    "\tout_img[lefty, leftx] = [255, 0, 0]\n",
    "\tout_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "\t# Plots the left and right polynomials on the lane lines\n",
    "\t#plt.plot(left_fitx, ploty, color='yellow')\n",
    "\t#plt.plot(right_fitx, ploty, color='yellow')\n",
    "\tleftfitpt = np.array([leftfitpt],np.int32)\n",
    "\trightfitpt = np.array([rightfitpt],np.int32)\n",
    "\tleftfitpt.reshape((-1,1,2))\n",
    "\trightfitpt.reshape((-1,1,2))\n",
    "\tout_img = cv2.polylines(out_img,[leftfitpt],False,(0,255,255),2)\n",
    "\tout_img = cv2.polylines(out_img,[rightfitpt],False,(0,255,255),2)\n",
    "\treturn out_img, left_fit, right_fit\n",
    "\n",
    "def search_around_poly(img, left_fit, right_fit):\n",
    "\tmargin = 10\n",
    "\tnonzero = img.nonzero()\n",
    "\tnonzeroy = np.array(nonzero[0])\n",
    "\tnonzerox = np.array(nonzero[1])\n",
    "\n",
    "\tleft_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "\tright_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "\tleftx = nonzerox[left_lane_inds]\n",
    "\tlefty = nonzeroy[left_lane_inds] \n",
    "\trightx = nonzerox[right_lane_inds]\n",
    "\trighty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\tleft_fit = np.polyfit(lefty, leftx, 2)\n",
    "\tright_fit = np.polyfit(righty, rightx, 2)\n",
    "\t# Fit new polynomials\n",
    "\tploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "\tleft_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "\tright_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "\t## Visualization ##\n",
    "\t# Create an image to draw on and an image to show the selection window\n",
    "\tout_img = np.dstack((img, img, img))*255\n",
    "\twindow_img = np.zeros_like(out_img)\n",
    "\t# Color in left and right line pixels\n",
    "\tout_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "\tout_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "\t# Generate a polygon to illustrate the search window area\n",
    "\t# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "\tleft_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "\tleft_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin,ploty])))])\n",
    "\tleft_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\tright_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "\tright_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin,ploty])))])\n",
    "\tright_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "\t# Draw the lane onto the warped blank image\n",
    "\tcv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "\tcv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "\tresult = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "\t# Plot the polynomial lines onto the image\n",
    "\tleftfitpt = []\n",
    "\trightfitpt = []\n",
    "\tfor i in range(len(ploty)):\n",
    "\t\tleftfitpt.append([left_fitx[i],ploty[i]])\n",
    "\t\trightfitpt.append([right_fitx[i],ploty[i]])\n",
    "\t\n",
    "\t#plt.plot(left_fitx, ploty, color='yellow')\n",
    "\t#plt.plot(right_fitx, ploty, color='yellow')\n",
    "\tleftfitpt = np.array([leftfitpt],np.int32)\n",
    "\trightfitpt = np.array([rightfitpt],np.int32)\n",
    "\tleftfitpt.reshape((-1,1,2))\n",
    "\trightfitpt.reshape((-1,1,2))\n",
    "\tresult = cv2.polylines(result,[leftfitpt],False,(0,255,255),2)\n",
    "\tresult = cv2.polylines(result,[rightfitpt],False,(0,255,255),2)\n",
    "\t## End visualization steps ##\n",
    "\treturn result, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure the curvature and transform to normal view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(img, left_fit, right_fit):\n",
    "\tym_per_pix = 30/720\n",
    "\txm_per_pix = 3.7/(img.shape[1]/2+250)\n",
    "\tploty = np.linspace(0,img.shape[0]-1, img.shape[0])\n",
    "\tleft_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "\tright_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\tleft_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "\tright_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "\ty_eval = np.max(ploty)\n",
    "\tleft_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "\tright_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\treturn left_curverad, right_curverad\n",
    "\n",
    "def normal_view_transform(img, undist, warped, left_fit, right_fit, Minv):\n",
    "\twarp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "\tcolor_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "\tploty = np.linspace(0,img.shape[0]-1, img.shape[0])\n",
    "\tleft_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "\tright_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "\tpts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "\tpts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "\n",
    "\tpts = np.hstack((pts_left, pts_right))\n",
    "\tcv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\tnewwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "\tresult = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run all the functions in that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ac2769310dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_video.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#fourcc = cv2.VideoWriter_fourcc(*'mp4v')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#out = cv2.VideoWriter('output.mp4',fourcc, 30.0, (720,1280))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#out = cv2.VideoWriter('output.mp4',fourcc, 30.0, (720,1280))\n",
    "objpoints, imgpoints = calibrate()\n",
    "i = 0\n",
    "while cap.isOpened():\n",
    "\tret, frame = cap.read()\n",
    "\tif i < 0:\n",
    "\t\ti += 1\n",
    "\t\tcontinue\n",
    "\tif ret == False:\n",
    "\t\tbreak\n",
    "\t#frame = cv2.imread('test_images/test6.jpg')\n",
    "\tundist = undistort(frame, objpoints, imgpoints)\n",
    "\thls = hls_pipeline(undist)\n",
    "\tunwarped, perspective_M, Minv = unwarp_image(hls)\n",
    "\tif i == 0:\n",
    "\t\tout_img, left_fit, right_fit = fit_polynomial(unwarped)\n",
    "\telse:\n",
    "\t\tresult, left_fit, right_fit = search_around_poly(unwarped, left_fit, right_fit)\n",
    "\t#don't use the following\n",
    "\t#convolved_result = convolution(unwarped)\n",
    "\tleft_curverad, right_curverad = measure_curvature_real(frame, left_fit, right_fit)\n",
    "\tfinal_output = normal_view_transform(frame, undist, unwarped, left_fit, right_fit, Minv)\n",
    "\tprint(left_curverad, right_curverad)\n",
    "\tleft_fitx = left_fit[0]*(frame.shape[0]-1)**2 + left_fit[1]*(frame.shape[0]-1) + left_fit[2]\n",
    "\tright_fitx = right_fit[0]*(frame.shape[0]-1)**2 + right_fit[1]*(frame.shape[0]-1) + right_fit[2]\n",
    "\tdistance = (frame.shape[1]/2 - (left_fitx+right_fitx)/2)*3.7/(frame.shape[1]/2+250)\n",
    "\tprint(distance)\n",
    "\tcv2.imshow('frame', final_output)\n",
    "\tcv2.imwrite('output/final'+str(i)+'.jpg',final_output)\n",
    "\t#out.write(final_output)\n",
    "\ti+=1\n",
    "#cv2.imwrite('final.jpg',final_output)\n",
    "#cv2.imwrite('original.jpg',frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
